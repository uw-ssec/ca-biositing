{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Notebook for CA Biositing Project\n",
    "\n",
    "This notebook provides a documented walkthrough of the ETL (Extract, Transform, Load) process for the CA Biositing project. It is designed for interactive development and exploration before migrating logic into the production pipeline.\n",
    "\n",
    "It covers:\n",
    "\n",
    "1.  **Setup**: Importing necessary libraries and establishing a connection to the database.\n",
    "2.  **Extraction**: Pulling raw data from Google Sheets.\n",
    "3.  **Cleaning**: Standardizing data types, handling missing values, and cleaning column names.\n",
    "4.  **Normalization**: Replacing human-readable names (e.g., \"Corn\") with database foreign key IDs (e.g., `resource_id: 1`).\n",
    "5.  **Utilities**: Common functions for data manipulation and analysis.\n",
    "6.  **Deployment Plan**: A step-by-step guide for moving the code from this notebook into the production ETL modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 08:53:57,422 - INFO - Project root '/Users/pjsmitty301/ca-biositing' is already in sys.path\n",
      "2026-01-04 08:53:57,423 - INFO - Successfully imported all project modules.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor as jn\n",
    "import logging\n",
    "from IPython.display import display\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import select\n",
    "\n",
    "# --- Basic Logging Configuration for Notebook ---\n",
    "# When running in a notebook, we use Python's standard logging.\n",
    "# In the production pipeline, this will be replaced by Prefect's `get_run_logger()`\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- Robustly find the project root ---\n",
    "# This ensures that the notebook can be run from any directory within the project.\n",
    "path = os.getcwd()\n",
    "project_root = None\n",
    "while path != os.path.dirname(path):\n",
    "    if 'pixi.toml' in os.listdir(path):\n",
    "        project_root = path\n",
    "        break\n",
    "    path = os.path.dirname(path)\n",
    "\n",
    "if not project_root:\n",
    "    raise FileNotFoundError(\"Could not find project root containing 'pixi.toml'.\")\n",
    "\n",
    "# Add the project root to the Python path to allow for module imports\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    logger.info(f\"Added project root '{project_root}' to sys.path\")\n",
    "else:\n",
    "    logger.info(f\"Project root '{project_root}' is already in sys.path\")\n",
    "\n",
    "# --- Import project modules ---\n",
    "try:\n",
    "    from src.ca_biositing.pipeline.ca_biositing.pipeline.utils.engine import engine\n",
    "    from src.ca_biositing.datamodels.ca_biositing.datamodels.schemas.generated.ca_biositing import *\n",
    "    from src.ca_biositing.pipeline.ca_biositing.pipeline.utils.name_id_swap import replace_name_with_id_df\n",
    "    from src.ca_biositing.pipeline.ca_biositing.pipeline.etl.extract import proximate, ultimate, cmpana\n",
    "    logger.info('Successfully imported all project modules.')\n",
    "except ImportError as e:\n",
    "    logger.error(f'Failed to import project modules: {e}', exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_gsheets(df):\n",
    "    \"\"\"Cleans and standardizes a DataFrame extracted from Google Sheets.\n",
    "\n",
    "    This function performs several key operations:\n",
    "    1. Cleans column names to a standard format (snake_case).\n",
    "    2. Drops rows where essential columns ('repl_no', 'value') are empty.\n",
    "    3. Coerces data types for numeric and datetime columns, handling errors gracefully.\n",
    "    4. Converts remaining columns to the best possible data types.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The raw DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info('Starting DataFrame cleaning process.')\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        logger.error('Input is not a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 1. Clean names and drop rows with missing essential data\n",
    "        df_cleaned = df.clean_names().dropna(subset=['repl_no', 'value'])\n",
    "        logger.info(f'Dropped {len(df) - len(df_cleaned)} rows with missing values.')\n",
    "\n",
    "        # 2. Coerce numeric types\n",
    "        df_cleaned['repl_no'] = pd.to_numeric(df_cleaned['repl_no'], errors='coerce').astype('Int32')\n",
    "        df_cleaned['value'] = pd.to_numeric(df_cleaned['value'], errors='coerce').astype(np.float32)\n",
    "\n",
    "        # 3. Coerce datetime types\n",
    "        if 'created_at' in df_cleaned.columns:\n",
    "            df_cleaned['created_at'] = pd.to_datetime(df_cleaned['created_at'], errors='coerce')\n",
    "        if 'updated_at' in df_cleaned.columns:\n",
    "            df_cleaned['updated_at'] = pd.to_datetime(df_cleaned['updated_at'], errors='coerce')\n",
    "\n",
    "        # 4. Convert other dtypes to best possible\n",
    "        df_cleaned = df_cleaned.convert_dtypes()\n",
    "        logger.info('Successfully cleaned DataFrame.')\n",
    "      \n",
    "    \n",
    "        # 5. Convert all string data to lowercase\n",
    "        df_cleaned = df_cleaned.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
    "        logger.info('Converted all string data to lowercase.')\n",
    "        return df_cleaned\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f'An error occurred during DataFrame cleaning: {e}', exc_info=True)\n",
    "        return None\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframes(dataframes, normalize_columns):\n",
    "    \"\"\"Normalizes a list of DataFrames by replacing name columns with foreign key IDs.\n",
    "\n",
    "    This function iterates through a list of dataframes and, for each one, iterates\n",
    "    through a dictionary of columns that need to be normalized. It uses the \n",
    "    `replace_name_with_id_df` utility to look up or create the corresponding ID\n",
    "    in the database.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list[pd.DataFrame]): A list of DataFrames to normalize.\n",
    "        normalize_columns (dict): A dictionary mapping column names to SQLModel classes and attributes.\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: The list of normalized DataFrames.\n",
    "    \"\"\"\n",
    "    logger.info(f'Starting normalization process for {len(dataframes)} dataframes.')\n",
    "    normalized_dfs = []\n",
    "    try:\n",
    "        with Session(engine) as db:\n",
    "            for i, df in enumerate(dataframes):\n",
    "                if not isinstance(df, pd.DataFrame):\n",
    "                    logger.warning(f'Item {i+1} is not a DataFrame, skipping.')\n",
    "                    continue\n",
    "                \n",
    "                logger.info(f'Processing DataFrame #{i+1} with {len(df)} rows.')\n",
    "                df_normalized = df.copy()\n",
    "\n",
    "                for df_col, (model, model_name_attr) in normalize_columns.items():\n",
    "                    if df_col not in df_normalized.columns:\n",
    "                        logger.warning(f\"Column '{df_col}' not in DataFrame #{i+1}. Skipping normalization for this column.\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        logger.info(f\"Normalizing column '{df_col}' using model '{model.__name__}'.\")\n",
    "                        df_normalized = replace_name_with_id_df(\n",
    "                            db=db,\n",
    "                            df=df_normalized,\n",
    "                            ref_model=model,\n",
    "                            df_name_column=df_col,\n",
    "                            model_name_attr=model_name_attr,\n",
    "                            id_column_name='id',\n",
    "                            final_column_name=f'{df_col}_id'\n",
    "                        )\n",
    "                        new_col_name = f'{df_col}_id'\n",
    "                        num_nulls = df_normalized[new_col_name].isnull().sum()\n",
    "                        logger.info(f\"Successfully normalized '{df_col}'. New column '{new_col_name}' contains {num_nulls} null values.\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error normalizing column '{df_col}' in DataFrame #{i+1}: {e}\", exc_info=True)\n",
    "                        continue # Continue to the next column\n",
    "                \n",
    "                normalized_dfs.append(df_normalized)\n",
    "                logger.info(f'Finished processing DataFrame #{i+1}.')\n",
    "            \n",
    "            logger.info('Committing database session.')\n",
    "            db.commit()\n",
    "            logger.info('Database commit successful.')\n",
    "    except Exception as e:\n",
    "        logger.error(f'A critical error occurred during the database session: {e}', exc_info=True)\n",
    "        db.rollback()\n",
    "        logger.info('Database session rolled back.')\n",
    "        \n",
    "    return normalized_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Execution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 08:58:52,849 - INFO - Starting data extraction...\n",
      "2026-01-04 08:58:52,865 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/admin/version \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 08:58:52,877 - INFO - Extracting raw data from '03.1-Proximate' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n",
      "2026-01-04 08:58:54,699 - INFO - Successfully extracted raw data.\n",
      "2026-01-04 08:58:54,703 - INFO - Finished in state Completed()\n",
      "2026-01-04 08:58:54,724 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/admin/version \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 08:58:54,736 - INFO - Extracting raw data from '03.7-Ultimate' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n",
      "2026-01-04 08:58:55,992 - INFO - Successfully extracted raw data.\n",
      "2026-01-04 08:58:55,996 - INFO - Finished in state Completed()\n",
      "2026-01-04 08:58:56,016 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/admin/version \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 08:58:56,029 - INFO - Extracting raw data from '03.3-CmpAna' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n",
      "2026-01-04 08:58:57,291 - INFO - Successfully extracted raw data.\n",
      "2026-01-04 08:58:57,294 - INFO - Finished in state Completed()\n",
      "2026-01-04 08:58:57,296 - INFO - Data extraction complete.\n",
      "2026-01-04 08:58:57,299 - INFO - Starting data cleaning...\n",
      "2026-01-04 08:58:57,299 - INFO - Starting DataFrame cleaning process.\n",
      "2026-01-04 08:58:57,302 - INFO - Dropped 0 rows with missing values.\n",
      "2026-01-04 08:58:57,309 - INFO - Successfully cleaned DataFrame.\n",
      "/var/folders/2l/qpqn5_6578z142wxn32lbtw00000gn/T/ipykernel_25314/183192953.py:42: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df_cleaned.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "2026-01-04 08:58:57,314 - INFO - Converted all string data to lowercase.\n",
      "2026-01-04 08:58:57,315 - INFO - Starting DataFrame cleaning process.\n",
      "2026-01-04 08:58:57,316 - INFO - Dropped 0 rows with missing values.\n",
      "2026-01-04 08:58:57,319 - INFO - Successfully cleaned DataFrame.\n",
      "/var/folders/2l/qpqn5_6578z142wxn32lbtw00000gn/T/ipykernel_25314/183192953.py:42: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df_cleaned.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "2026-01-04 08:58:57,320 - INFO - Converted all string data to lowercase.\n",
      "2026-01-04 08:58:57,321 - INFO - Starting DataFrame cleaning process.\n",
      "2026-01-04 08:58:57,325 - INFO - Dropped 0 rows with missing values.\n",
      "2026-01-04 08:58:57,335 - INFO - Successfully cleaned DataFrame.\n",
      "/var/folders/2l/qpqn5_6578z142wxn32lbtw00000gn/T/ipykernel_25314/183192953.py:42: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df_cleaned.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "2026-01-04 08:58:57,340 - INFO - Converted all string data to lowercase.\n",
      "2026-01-04 08:58:57,342 - INFO - Data cleaning complete.\n",
      "2026-01-04 08:58:57,342 - INFO - Starting data normalization...\n",
      "2026-01-04 08:58:57,343 - INFO - Starting normalization process for 3 dataframes.\n",
      "2026-01-04 08:58:57,343 - INFO - Processing DataFrame #1 with 759 rows.\n",
      "2026-01-04 08:58:57,344 - INFO - Normalizing column 'resource' using model 'Resource'.\n",
      "2026-01-04 08:58:57,355 - INFO - Successfully normalized 'resource'. New column 'resource_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,356 - INFO - Normalizing column 'prepared_sample' using model 'PreparedSample'.\n",
      "2026-01-04 08:58:57,367 - INFO - Successfully normalized 'prepared_sample'. New column 'prepared_sample_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,367 - INFO - Normalizing column 'preparation_method' using model 'PreparationMethod'.\n",
      "2026-01-04 08:58:57,369 - INFO - Successfully normalized 'preparation_method'. New column 'preparation_method_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,369 - INFO - Normalizing column 'parameter' using model 'Parameter'.\n",
      "2026-01-04 08:58:57,372 - INFO - Successfully normalized 'parameter'. New column 'parameter_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,372 - INFO - Normalizing column 'unit' using model 'Unit'.\n",
      "2026-01-04 08:58:57,374 - INFO - Successfully normalized 'unit'. New column 'unit_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,374 - INFO - Normalizing column 'analyst_email' using model 'Contact'.\n",
      "2026-01-04 08:58:57,375 - INFO - Successfully normalized 'analyst_email'. New column 'analyst_email_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,375 - INFO - Normalizing column 'analysis_type' using model 'AnalysisType'.\n",
      "2026-01-04 08:58:57,379 - INFO - Successfully normalized 'analysis_type'. New column 'analysis_type_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,379 - WARNING - Column 'primary_ag_product' not in DataFrame #1. Skipping normalization for this column.\n",
      "2026-01-04 08:58:57,379 - INFO - Finished processing DataFrame #1.\n",
      "2026-01-04 08:58:57,379 - INFO - Processing DataFrame #2 with 64 rows.\n",
      "2026-01-04 08:58:57,380 - INFO - Normalizing column 'resource' using model 'Resource'.\n",
      "2026-01-04 08:58:57,384 - INFO - Successfully normalized 'resource'. New column 'resource_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,384 - INFO - Normalizing column 'prepared_sample' using model 'PreparedSample'.\n",
      "2026-01-04 08:58:57,388 - INFO - Successfully normalized 'prepared_sample'. New column 'prepared_sample_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,388 - INFO - Normalizing column 'preparation_method' using model 'PreparationMethod'.\n",
      "2026-01-04 08:58:57,392 - INFO - Successfully normalized 'preparation_method'. New column 'preparation_method_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,392 - INFO - Normalizing column 'parameter' using model 'Parameter'.\n",
      "2026-01-04 08:58:57,396 - INFO - Successfully normalized 'parameter'. New column 'parameter_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,396 - INFO - Normalizing column 'unit' using model 'Unit'.\n",
      "2026-01-04 08:58:57,398 - INFO - Successfully normalized 'unit'. New column 'unit_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,398 - INFO - Normalizing column 'analyst_email' using model 'Contact'.\n",
      "2026-01-04 08:58:57,399 - INFO - Successfully normalized 'analyst_email'. New column 'analyst_email_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,400 - INFO - Normalizing column 'analysis_type' using model 'AnalysisType'.\n",
      "2026-01-04 08:58:57,403 - INFO - Successfully normalized 'analysis_type'. New column 'analysis_type_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,403 - WARNING - Column 'primary_ag_product' not in DataFrame #2. Skipping normalization for this column.\n",
      "2026-01-04 08:58:57,403 - INFO - Finished processing DataFrame #2.\n",
      "2026-01-04 08:58:57,403 - INFO - Processing DataFrame #3 with 390 rows.\n",
      "2026-01-04 08:58:57,404 - INFO - Normalizing column 'resource' using model 'Resource'.\n",
      "2026-01-04 08:58:57,406 - INFO - Successfully normalized 'resource'. New column 'resource_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,406 - INFO - Normalizing column 'prepared_sample' using model 'PreparedSample'.\n",
      "2026-01-04 08:58:57,408 - INFO - Successfully normalized 'prepared_sample'. New column 'prepared_sample_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,408 - INFO - Normalizing column 'preparation_method' using model 'PreparationMethod'.\n",
      "2026-01-04 08:58:57,409 - INFO - Successfully normalized 'preparation_method'. New column 'preparation_method_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,410 - INFO - Normalizing column 'parameter' using model 'Parameter'.\n",
      "2026-01-04 08:58:57,411 - INFO - Successfully normalized 'parameter'. New column 'parameter_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,411 - INFO - Normalizing column 'unit' using model 'Unit'.\n",
      "2026-01-04 08:58:57,413 - INFO - Successfully normalized 'unit'. New column 'unit_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,413 - INFO - Normalizing column 'analyst_email' using model 'Contact'.\n",
      "2026-01-04 08:58:57,415 - INFO - Successfully normalized 'analyst_email'. New column 'analyst_email_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,415 - INFO - Normalizing column 'analysis_type' using model 'AnalysisType'.\n",
      "2026-01-04 08:58:57,416 - INFO - Successfully normalized 'analysis_type'. New column 'analysis_type_id' contains 0 null values.\n",
      "2026-01-04 08:58:57,416 - WARNING - Column 'primary_ag_product' not in DataFrame #3. Skipping normalization for this column.\n",
      "2026-01-04 08:58:57,417 - INFO - Finished processing DataFrame #3.\n",
      "2026-01-04 08:58:57,417 - INFO - Committing database session.\n",
      "2026-01-04 08:58:57,418 - INFO - Database commit successful.\n",
      "2026-01-04 08:58:57,418 - INFO - Data normalization complete.\n",
      "2026-01-04 08:58:57,418 - INFO - Displaying results of normalization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Normalized DataFrame 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prox_uuid_031",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "record_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_codename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "storage_cond",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exper_abbrev",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "repl_no",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "repl_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "qc_result",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "upload_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "note",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resource_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepared_sample_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preparation_method_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parameter_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unit_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analyst_email_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analysis_type_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e2d8eb1c-3fc8-4b97-99b0-df76b598d9df",
       "rows": [
        [
         "0",
         "d7965110-407f-e356-d41d-b3b9a2b7b7",
         "(73)b7b7",
         "oakleaf",
         "4c",
         "prox01xk",
         "1.0",
         "prox01xk(73)1",
         "61.849998474121094",
         "2024-10-02 10:31:01",
         null,
         "pass",
         "not ready",
         "",
         "24",
         "109",
         "7",
         "25",
         "1",
         "1",
         "6"
        ],
        [
         "1",
         "c8fea984-2e9a-8def-55fb-1a9d7d9ba8",
         "(73)9ba8",
         "oakleaf",
         "4c",
         "prox01xk",
         "2.0",
         "prox01xk(73)2",
         "63.209999084472656",
         "2024-10-02 10:31:31",
         null,
         "pass",
         "ready",
         "",
         "24",
         "109",
         "7",
         "25",
         "1",
         "1",
         "6"
        ],
        [
         "2",
         "df304d5d-3a85-4881-7142-6d4e5f957d",
         "(73)957d",
         "oakleaf",
         "4c",
         "prox01xk",
         "3.0",
         "prox01xk(73)3",
         "63.27000045776367",
         "2024-10-02 10:32:01",
         null,
         "pass",
         "imported",
         "",
         "24",
         "109",
         "7",
         "25",
         "1",
         "1",
         "6"
        ],
        [
         "3",
         "01c6c5be-cea6-54af-3924-b0bad69335",
         "(73)9335",
         "oakleaf",
         "4c",
         "prox01xk",
         "1.0",
         "prox01xk(73)1",
         "0.6899999976158142",
         "2024-10-03 10:31:01",
         null,
         "pass",
         "import failed",
         "",
         "24",
         "109",
         "7",
         "23",
         "1",
         "1",
         "6"
        ],
        [
         "4",
         "126745c7-dd41-2f6d-0dc5-28dbca415f",
         "(73)415f",
         "oakleaf",
         "4c",
         "prox01xk",
         "2.0",
         "prox01xk(73)2",
         "0.8899999856948853",
         "2024-10-03 10:31:31",
         null,
         "pass",
         "",
         "",
         "24",
         "109",
         "7",
         "23",
         "1",
         "1",
         "6"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prox_uuid_031</th>\n",
       "      <th>record_id</th>\n",
       "      <th>source_codename</th>\n",
       "      <th>storage_cond</th>\n",
       "      <th>exper_abbrev</th>\n",
       "      <th>repl_no</th>\n",
       "      <th>repl_id</th>\n",
       "      <th>value</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>qc_result</th>\n",
       "      <th>upload_status</th>\n",
       "      <th>note</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>prepared_sample_id</th>\n",
       "      <th>preparation_method_id</th>\n",
       "      <th>parameter_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>analyst_email_id</th>\n",
       "      <th>analysis_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7965110-407f-e356-d41d-b3b9a2b7b7</td>\n",
       "      <td>(73)b7b7</td>\n",
       "      <td>oakleaf</td>\n",
       "      <td>4c</td>\n",
       "      <td>prox01xk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prox01xk(73)1</td>\n",
       "      <td>61.849998</td>\n",
       "      <td>2024-10-02 10:31:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>not ready</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c8fea984-2e9a-8def-55fb-1a9d7d9ba8</td>\n",
       "      <td>(73)9ba8</td>\n",
       "      <td>oakleaf</td>\n",
       "      <td>4c</td>\n",
       "      <td>prox01xk</td>\n",
       "      <td>2.0</td>\n",
       "      <td>prox01xk(73)2</td>\n",
       "      <td>63.209999</td>\n",
       "      <td>2024-10-02 10:31:31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>ready</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df304d5d-3a85-4881-7142-6d4e5f957d</td>\n",
       "      <td>(73)957d</td>\n",
       "      <td>oakleaf</td>\n",
       "      <td>4c</td>\n",
       "      <td>prox01xk</td>\n",
       "      <td>3.0</td>\n",
       "      <td>prox01xk(73)3</td>\n",
       "      <td>63.270000</td>\n",
       "      <td>2024-10-02 10:32:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>imported</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01c6c5be-cea6-54af-3924-b0bad69335</td>\n",
       "      <td>(73)9335</td>\n",
       "      <td>oakleaf</td>\n",
       "      <td>4c</td>\n",
       "      <td>prox01xk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prox01xk(73)1</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>2024-10-03 10:31:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>import failed</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126745c7-dd41-2f6d-0dc5-28dbca415f</td>\n",
       "      <td>(73)415f</td>\n",
       "      <td>oakleaf</td>\n",
       "      <td>4c</td>\n",
       "      <td>prox01xk</td>\n",
       "      <td>2.0</td>\n",
       "      <td>prox01xk(73)2</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>2024-10-03 10:31:31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        prox_uuid_031 record_id source_codename storage_cond  \\\n",
       "0  d7965110-407f-e356-d41d-b3b9a2b7b7  (73)b7b7         oakleaf           4c   \n",
       "1  c8fea984-2e9a-8def-55fb-1a9d7d9ba8  (73)9ba8         oakleaf           4c   \n",
       "2  df304d5d-3a85-4881-7142-6d4e5f957d  (73)957d         oakleaf           4c   \n",
       "3  01c6c5be-cea6-54af-3924-b0bad69335  (73)9335         oakleaf           4c   \n",
       "4  126745c7-dd41-2f6d-0dc5-28dbca415f  (73)415f         oakleaf           4c   \n",
       "\n",
       "  exper_abbrev  repl_no        repl_id      value          created_at  \\\n",
       "0     prox01xk      1.0  prox01xk(73)1  61.849998 2024-10-02 10:31:01   \n",
       "1     prox01xk      2.0  prox01xk(73)2  63.209999 2024-10-02 10:31:31   \n",
       "2     prox01xk      3.0  prox01xk(73)3  63.270000 2024-10-02 10:32:01   \n",
       "3     prox01xk      1.0  prox01xk(73)1   0.690000 2024-10-03 10:31:01   \n",
       "4     prox01xk      2.0  prox01xk(73)2   0.890000 2024-10-03 10:31:31   \n",
       "\n",
       "  updated_at qc_result  upload_status note  resource_id  prepared_sample_id  \\\n",
       "0        NaT      pass      not ready                24                 109   \n",
       "1        NaT      pass          ready                24                 109   \n",
       "2        NaT      pass       imported                24                 109   \n",
       "3        NaT      pass  import failed                24                 109   \n",
       "4        NaT      pass                               24                 109   \n",
       "\n",
       "   preparation_method_id  parameter_id  unit_id  analyst_email_id  \\\n",
       "0                      7            25        1                 1   \n",
       "1                      7            25        1                 1   \n",
       "2                      7            25        1                 1   \n",
       "3                      7            23        1                 1   \n",
       "4                      7            23        1                 1   \n",
       "\n",
       "   analysis_type_id  \n",
       "0                 6  \n",
       "1                 6  \n",
       "2                 6  \n",
       "3                 6  \n",
       "4                 6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Normalized DataFrame 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ult_uuid_037",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "record_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ult_sample_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "storage_cond",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exper_abbrev",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "repl_no",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repl_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "qc_result",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "note",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "equipment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw_data_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "upload_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resource_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepared_sample_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preparation_method_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parameter_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unit_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analyst_email_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analysis_type_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "323960ff-b723-432d-b7c9-fa0f9dd8c185",
       "rows": [
        [
         "0",
         "421617a5-e50e-9642-2974-b3275fe822",
         ")u22e822",
         "hum-almhu023km2(15)u22",
         "rt vacuum sealed",
         "ult26kh",
         "1",
         "ult26kh(15)1",
         "88.5999984741211",
         null,
         null,
         "pass",
         "1",
         "",
         "",
         "",
         "8",
         "80",
         "6",
         "28",
         "3",
         "2",
         "7"
        ],
        [
         "1",
         "7e7919c2-5db4-6bef-75e2-7e51321200",
         ")u001200",
         "hum-almhu023km2(15)u00",
         "rt vacuum sealed",
         "ult26kh",
         "1",
         "ult26kh(15)1",
         null,
         null,
         null,
         "fail",
         " 1 dup",
         "",
         "",
         "",
         "8",
         "80",
         "6",
         "28",
         "3",
         "2",
         "7"
        ],
        [
         "2",
         "3aa85881-1185-642f-c44b-41ad2275d2",
         ")ud275d2",
         "hum-almsh022km2(13)ud2",
         "rt vacuum sealed",
         "ult26kh",
         "1",
         "ult26kh(13)1",
         "81.30000305175781",
         null,
         null,
         "pass",
         "2",
         "",
         "",
         "",
         "26",
         "96",
         "6",
         "28",
         "3",
         "2",
         "7"
        ],
        [
         "3",
         "fa418804-6c4f-4c90-d78f-84d7df54d3",
         ")ud354d3",
         "ene-wash017okm2(82)ud3",
         "rt vacuum sealed",
         "ult26kh",
         "1",
         "ult26kh(82)1",
         "92.19999694824219",
         null,
         null,
         "pass",
         "3",
         "",
         "",
         "",
         "2",
         "91",
         "9",
         "28",
         "3",
         "2",
         "7"
        ],
        [
         "4",
         "6fdacbfc-7e0b-473b-444f-85b7650267",
         ")u670267",
         "ebo-gppm010okm2(1b)u67",
         "rt vacuum sealed",
         "ult26kh",
         "1",
         "ult26kh(1b)1",
         "93.80000305175781",
         null,
         null,
         "pass",
         "4",
         "",
         "",
         "",
         "7",
         "153",
         "9",
         "28",
         "3",
         "2",
         "7"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ult_uuid_037</th>\n",
       "      <th>record_id</th>\n",
       "      <th>ult_sample_name</th>\n",
       "      <th>storage_cond</th>\n",
       "      <th>exper_abbrev</th>\n",
       "      <th>repl_no</th>\n",
       "      <th>repl_id</th>\n",
       "      <th>value</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>...</th>\n",
       "      <th>equipment</th>\n",
       "      <th>raw_data_url</th>\n",
       "      <th>upload_status</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>prepared_sample_id</th>\n",
       "      <th>preparation_method_id</th>\n",
       "      <th>parameter_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>analyst_email_id</th>\n",
       "      <th>analysis_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421617a5-e50e-9642-2974-b3275fe822</td>\n",
       "      <td>)u22e822</td>\n",
       "      <td>hum-almhu023km2(15)u22</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>ult26kh</td>\n",
       "      <td>1</td>\n",
       "      <td>ult26kh(15)1</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7e7919c2-5db4-6bef-75e2-7e51321200</td>\n",
       "      <td>)u001200</td>\n",
       "      <td>hum-almhu023km2(15)u00</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>ult26kh</td>\n",
       "      <td>1</td>\n",
       "      <td>ult26kh(15)1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3aa85881-1185-642f-c44b-41ad2275d2</td>\n",
       "      <td>)ud275d2</td>\n",
       "      <td>hum-almsh022km2(13)ud2</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>ult26kh</td>\n",
       "      <td>1</td>\n",
       "      <td>ult26kh(13)1</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa418804-6c4f-4c90-d78f-84d7df54d3</td>\n",
       "      <td>)ud354d3</td>\n",
       "      <td>ene-wash017okm2(82)ud3</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>ult26kh</td>\n",
       "      <td>1</td>\n",
       "      <td>ult26kh(82)1</td>\n",
       "      <td>92.199997</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6fdacbfc-7e0b-473b-444f-85b7650267</td>\n",
       "      <td>)u670267</td>\n",
       "      <td>ebo-gppm010okm2(1b)u67</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>ult26kh</td>\n",
       "      <td>1</td>\n",
       "      <td>ult26kh(1b)1</td>\n",
       "      <td>93.800003</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>153</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ult_uuid_037 record_id         ult_sample_name  \\\n",
       "0  421617a5-e50e-9642-2974-b3275fe822  )u22e822  hum-almhu023km2(15)u22   \n",
       "1  7e7919c2-5db4-6bef-75e2-7e51321200  )u001200  hum-almhu023km2(15)u00   \n",
       "2  3aa85881-1185-642f-c44b-41ad2275d2  )ud275d2  hum-almsh022km2(13)ud2   \n",
       "3  fa418804-6c4f-4c90-d78f-84d7df54d3  )ud354d3  ene-wash017okm2(82)ud3   \n",
       "4  6fdacbfc-7e0b-473b-444f-85b7650267  )u670267  ebo-gppm010okm2(1b)u67   \n",
       "\n",
       "       storage_cond exper_abbrev  repl_no       repl_id      value created_at  \\\n",
       "0  rt vacuum sealed      ult26kh        1  ult26kh(15)1  88.599998        NaT   \n",
       "1  rt vacuum sealed      ult26kh        1  ult26kh(15)1        NaN        NaT   \n",
       "2  rt vacuum sealed      ult26kh        1  ult26kh(13)1  81.300003        NaT   \n",
       "3  rt vacuum sealed      ult26kh        1  ult26kh(82)1  92.199997        NaT   \n",
       "4  rt vacuum sealed      ult26kh        1  ult26kh(1b)1  93.800003        NaT   \n",
       "\n",
       "  updated_at  ... equipment raw_data_url upload_status resource_id  \\\n",
       "0        NaT  ...                                                8   \n",
       "1        NaT  ...                                                8   \n",
       "2        NaT  ...                                               26   \n",
       "3        NaT  ...                                                2   \n",
       "4        NaT  ...                                                7   \n",
       "\n",
       "  prepared_sample_id  preparation_method_id  parameter_id  unit_id  \\\n",
       "0                 80                      6            28        3   \n",
       "1                 80                      6            28        3   \n",
       "2                 96                      6            28        3   \n",
       "3                 91                      9            28        3   \n",
       "4                153                      9            28        3   \n",
       "\n",
       "   analyst_email_id  analysis_type_id  \n",
       "0                 2                 7  \n",
       "1                 2                 7  \n",
       "2                 2                 7  \n",
       "3                 2                 7  \n",
       "4                 2                 7  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Normalized DataFrame 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cmp_uuid_033",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "record_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "storage_cond",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exper_abbrev",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "repl_no",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repl_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "qc_result",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "note",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "equipment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw_data_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "upload_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resource_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepared_sample_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preparation_method_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parameter_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unit_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analyst_email_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "analysis_type_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "31e4fb08-8acb-41fc-bdec-4f79aea24d5f",
       "rows": [
        [
         "0",
         "3ee2993d-86e3-1f16-c7ea-f8d555e114",
         "(85)e114",
         "rt vacuum sealed",
         "cmp04xk",
         "1",
         "cmp04xk(85)1",
         "14.15999984741211",
         "2025-01-23 09:00:01",
         null,
         "pass",
         "",
         "",
         "",
         "ready",
         "24",
         "92",
         "8",
         "12",
         "2",
         "1",
         "3"
        ],
        [
         "1",
         "46878ef9-1226-22a0-d5d8-cf65e241cb",
         "(85)41cb",
         "rt vacuum sealed",
         "cmp04xk",
         "2",
         "cmp04xk(85)2",
         "14.180000305175781",
         "2025-01-23 09:00:16",
         null,
         "pass",
         "",
         "",
         "",
         "ready",
         "24",
         "92",
         "8",
         "12",
         "2",
         "1",
         "3"
        ],
        [
         "2",
         "76a7a2f4-c4e4-e60f-1187-dec6e02246",
         "(85)2246",
         "rt vacuum sealed",
         "cmp04xk",
         "3",
         "cmp04xk(85)3",
         "14.119999885559082",
         "2025-01-23 09:00:31",
         null,
         "pass",
         "",
         "",
         "",
         "ready",
         "24",
         "92",
         "8",
         "12",
         "2",
         "1",
         "3"
        ],
        [
         "3",
         "7a136832-286b-07cb-62de-acf52f9311",
         "(85)9311",
         "rt vacuum sealed",
         "cmp04xk",
         "1",
         "cmp04xk(85)1",
         "15.739999771118164",
         "2025-01-23 09:00:46",
         null,
         "pass",
         "",
         "",
         "",
         "ready",
         "24",
         "92",
         "8",
         "14",
         "2",
         "1",
         "3"
        ],
        [
         "4",
         "b709ecee-f9a6-a55d-a59e-93b7b863d7",
         "(85)63d7",
         "rt vacuum sealed",
         "cmp04xk",
         "2",
         "cmp04xk(85)2",
         "15.75",
         "2025-01-23 09:01:01",
         null,
         "pass",
         "",
         "",
         "",
         "ready",
         "24",
         "92",
         "8",
         "14",
         "2",
         "1",
         "3"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmp_uuid_033</th>\n",
       "      <th>record_id</th>\n",
       "      <th>storage_cond</th>\n",
       "      <th>exper_abbrev</th>\n",
       "      <th>repl_no</th>\n",
       "      <th>repl_id</th>\n",
       "      <th>value</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>qc_result</th>\n",
       "      <th>...</th>\n",
       "      <th>equipment</th>\n",
       "      <th>raw_data_url</th>\n",
       "      <th>upload_status</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>prepared_sample_id</th>\n",
       "      <th>preparation_method_id</th>\n",
       "      <th>parameter_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>analyst_email_id</th>\n",
       "      <th>analysis_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ee2993d-86e3-1f16-c7ea-f8d555e114</td>\n",
       "      <td>(85)e114</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>1</td>\n",
       "      <td>cmp04xk(85)1</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2025-01-23 09:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ready</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46878ef9-1226-22a0-d5d8-cf65e241cb</td>\n",
       "      <td>(85)41cb</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>2</td>\n",
       "      <td>cmp04xk(85)2</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2025-01-23 09:00:16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ready</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76a7a2f4-c4e4-e60f-1187-dec6e02246</td>\n",
       "      <td>(85)2246</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>3</td>\n",
       "      <td>cmp04xk(85)3</td>\n",
       "      <td>14.12</td>\n",
       "      <td>2025-01-23 09:00:31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ready</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a136832-286b-07cb-62de-acf52f9311</td>\n",
       "      <td>(85)9311</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>1</td>\n",
       "      <td>cmp04xk(85)1</td>\n",
       "      <td>15.74</td>\n",
       "      <td>2025-01-23 09:00:46</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ready</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b709ecee-f9a6-a55d-a59e-93b7b863d7</td>\n",
       "      <td>(85)63d7</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>2</td>\n",
       "      <td>cmp04xk(85)2</td>\n",
       "      <td>15.75</td>\n",
       "      <td>2025-01-23 09:01:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ready</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cmp_uuid_033 record_id      storage_cond  \\\n",
       "0  3ee2993d-86e3-1f16-c7ea-f8d555e114  (85)e114  rt vacuum sealed   \n",
       "1  46878ef9-1226-22a0-d5d8-cf65e241cb  (85)41cb  rt vacuum sealed   \n",
       "2  76a7a2f4-c4e4-e60f-1187-dec6e02246  (85)2246  rt vacuum sealed   \n",
       "3  7a136832-286b-07cb-62de-acf52f9311  (85)9311  rt vacuum sealed   \n",
       "4  b709ecee-f9a6-a55d-a59e-93b7b863d7  (85)63d7  rt vacuum sealed   \n",
       "\n",
       "  exper_abbrev  repl_no       repl_id  value          created_at updated_at  \\\n",
       "0      cmp04xk        1  cmp04xk(85)1  14.16 2025-01-23 09:00:01        NaT   \n",
       "1      cmp04xk        2  cmp04xk(85)2  14.18 2025-01-23 09:00:16        NaT   \n",
       "2      cmp04xk        3  cmp04xk(85)3  14.12 2025-01-23 09:00:31        NaT   \n",
       "3      cmp04xk        1  cmp04xk(85)1  15.74 2025-01-23 09:00:46        NaT   \n",
       "4      cmp04xk        2  cmp04xk(85)2  15.75 2025-01-23 09:01:01        NaT   \n",
       "\n",
       "  qc_result  ... equipment raw_data_url upload_status resource_id  \\\n",
       "0      pass  ...                                ready          24   \n",
       "1      pass  ...                                ready          24   \n",
       "2      pass  ...                                ready          24   \n",
       "3      pass  ...                                ready          24   \n",
       "4      pass  ...                                ready          24   \n",
       "\n",
       "   prepared_sample_id  preparation_method_id  parameter_id  unit_id  \\\n",
       "0                  92                      8            12        2   \n",
       "1                  92                      8            12        2   \n",
       "2                  92                      8            12        2   \n",
       "3                  92                      8            14        2   \n",
       "4                  92                      8            14        2   \n",
       "\n",
       "   analyst_email_id  analysis_type_id  \n",
       "0                 1                 3  \n",
       "1                 1                 3  \n",
       "2                 1                 3  \n",
       "3                 1                 3  \n",
       "4                 1                 3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Extraction ---\n",
    "# In a real Prefect flow, each extraction would be a separate task.\n",
    "logger.info('Starting data extraction...')\n",
    "prox_df = proximate.extract(project_root=project_root)\n",
    "ult_df = ultimate.extract(project_root=project_root)\n",
    "cmp_df = cmpana.extract(project_root=project_root)\n",
    "dataframes = [prox_df, ult_df, cmp_df]\n",
    "logger.info('Data extraction complete.')\n",
    "\n",
    "# --- 2. Cleaning ---\n",
    "# This list comprehension applies the cleaning function to each extracted dataframe.\n",
    "logger.info('Starting data cleaning...')\n",
    "clean_dataframes = [clean_the_gsheets(df) for df in dataframes if df is not None]\n",
    "logger.info('Data cleaning complete.')\n",
    "\n",
    "# --- 3. Normalization ---\n",
    "# This dictionary defines the columns to be normalized. \n",
    "# The key is the column name in the DataFrame.\n",
    "# The value is a tuple containing the corresponding SQLAlchemy model and the name of the attribute on the model to match against.\n",
    "NORMALIZE_COLUMNS = {\n",
    "    'resource': (Resource, 'name'),\n",
    "    'prepared_sample': (PreparedSample, 'name'),\n",
    "    'preparation_method': (PreparationMethod, 'name'),\n",
    "    'parameter': (Parameter, 'name'),\n",
    "    'unit': (Unit, 'name'),\n",
    "    'analyst_email': (Contact, 'email'),\n",
    "    'analysis_type': (AnalysisType, 'name'),\n",
    "    'primary_ag_product': (PrimaryAgProduct, 'name')\n",
    "}\n",
    "\n",
    "logger.info('Starting data normalization...')\n",
    "normalized_dataframes = normalize_dataframes(clean_dataframes, NORMALIZE_COLUMNS)\n",
    "logger.info('Data normalization complete.')\n",
    "\n",
    "# --- 4. Display Results ---\n",
    "logger.info('Displaying results of normalization...')\n",
    "for i, df in enumerate(normalized_dataframes):\n",
    "    print(f'--- Normalized DataFrame {i+1} ---')\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Plan\n",
    "\n",
    "The code in this notebook will be transitioned to the main ETL pipeline by following these steps:\n",
    "\n",
    "1.  **Function Migration**: The `clean_the_gsheets` and `normalize_dataframes` functions will be moved to a new utility module, for example, `src/ca_biositing/pipeline/ca_biositing/pipeline/utils/etl_utils.py`. Each function will be decorated with `@task` from Prefect to turn it into a reusable pipeline component.\n",
    "2.  **Flow Creation**: A new Prefect flow will be created in the `src/ca_biositing/pipeline/ca_biositing/pipeline/flows/` directory (e.g., `master_extraction_flow.py`). This flow will orchestrate the entire ETL process for a given data source.\n",
    "3.  **Task Integration**: The new flow will be composed of individual tasks. It will call the existing extraction tasks (`proximate.extract`, etc.), and then pass the results to the new cleaning and normalization tasks from `etl_utils.py`.\n",
    "4.  **Logging**: The `logging` module will be replaced with `get_run_logger()` from Prefect within the tasks to ensure logs are captured by the Prefect UI.\n",
    "5.  **Configuration**: The `NORMALIZE_COLUMNS` dictionary will be moved to a configuration file or defined within the relevant flow to make it easier to manage and modify without changing the code.\n",
    "6.  **Testing**: Unit tests will be written for the new utility functions in `etl_utils.py`. An integration test will be created for the new Prefect flow to ensure all the tasks work together correctly.\n",
    "7.  **Deployment**: Once the flow is complete and tested, it will be deployed to the Prefect server using the `pixi run deploy` command, making it available to be run on a schedule or manually via the UI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi Default Environment",
   "language": "python",
   "name": "pixi-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
