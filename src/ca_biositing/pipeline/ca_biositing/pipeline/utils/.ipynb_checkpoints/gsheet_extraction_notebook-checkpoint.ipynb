{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor as jn\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Robustly find the project root ---\n",
    "# The project root is the directory containing the 'pixi.toml' file.\n",
    "path = os.getcwd()\n",
    "project_root = None\n",
    "while path != os.path.dirname(path): # Stop at the filesystem root\n",
    "    if 'pixi.toml' in os.listdir(path):\n",
    "        project_root = path\n",
    "        break\n",
    "    path = os.path.dirname(path)\n",
    "\n",
    "if not project_root:\n",
    "    raise FileNotFoundError(\"Could not find project root containing 'pixi.toml'.\")\n",
    "\n",
    "# --- Add project root to sys.path ---\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added project root '{project_root}' to sys.path\")\n",
    "else:\n",
    "    print(f\"Project root '{project_root}' is already in sys.path\")\n",
    "\n",
    "# --- Import the module ---\n",
    "try:\n",
    "    from src.ca_biositing.pipeline.ca_biositing.pipeline.etl.extract import proximate, ultimate, cmpana\n",
    "    print(\"Successfully imported all module.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import modules: {e}\")\n",
    "    print(f\"\\nFull sys.path: {sys.path}\")\n",
    "\n",
    "# --- Run the extraction ---\n",
    "if 'proximate' in locals():\n",
    "    try:\n",
    "        # Pass the project_root to the extract function\n",
    "        df = proximate.extract(project_root=project_root)\n",
    "        if df is not None:\n",
    "            print(\"\\nSuccessfully extracted proximate data.\")\n",
    "            display(df.head())\n",
    "        else:\n",
    "            print(\"\\n Prox extraction returned no data. Check the logs above for errors.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during prox extraction: {e}\")\n",
    "\n",
    "if 'ultimate' in locals():\n",
    "    try:\n",
    "        df2 = ultimate.extract(project_root=project_root)\n",
    "        if df is not None:\n",
    "            print(\"\\nSuccessfully extracted Ultimate data.\")\n",
    "            display(df2.head())\n",
    "        else:\n",
    "            print(\"\\n Ultimate extraction returned no data. Check the logs above for errors.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during extraction: {e}\")\n",
    "\n",
    "if 'cmpana' in locals():\n",
    "    try:\n",
    "        df3 = cmpana.extract(project_root=project_root)\n",
    "        if df is not None:\n",
    "            print(\"\\nSuccessfully extracted CmpAna data.\")\n",
    "            display(df3.head())\n",
    "        else:\n",
    "            print(\"\\nCmpAna extraction returned no data. Check the logs above for errors.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during cmp ana extraction: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nCmp Ana extraction process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function seeks to clean the incoming gsheet dataframes and coerce the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_gsheets(df):\n",
    "    # 1. Clean names and drop rows\n",
    "    df = df.clean_names().dropna(subset=['repl_no', 'value'])\n",
    "\n",
    "    # 2. Coerce types (using errors='coerce' handles messy string data)\n",
    "    df['repl_no'] = pd.to_numeric(df['repl_no'], errors='coerce').astype('Int32') # Capital 'I' handles NaNs\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce').astype(np.float32)\n",
    "\n",
    "    # 3. Dates\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['updated_at'] = pd.to_datetime(df['updated_at'], errors='coerce')\n",
    "\n",
    "    # 4. Convert remaining objects to best possible types (like strings)\n",
    "    df = df.convert_dtypes()\n",
    "\n",
    "    # 5. Convert all string data to lowercase\n",
    "    df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
    "\n",
    "    # 6. Convert empty strings to NaN\n",
    "    df.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "    return df # Return the FULL dataframe, not just .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlmodel import Session, select, create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#This module queries the db via the ORM\n",
    "\n",
    "load_dotenv(dotenv_path=project_root + \"\\\\resources\\\\docker\\\\.env\")\n",
    "\n",
    "# Database Connection\n",
    "\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD= os.getenv(\"POSTGRES_PASSWORD\")\n",
    "\n",
    "# 2. Host Port Mapping\n",
    "# This is the port on your local machine that will connect to the container's port 5432.\n",
    "POSTGRES_PORT= os.getenv(\"POSTGRES_PORT\")\n",
    "\n",
    "DATABASE_URL = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@localhost:{POSTGRES_PORT}/biocirv_db\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "print(f\"Connected to database.\")\n",
    "\n",
    "primary_ag_product = pd.read_sql(\"SELECT * FROM primary_ag_product;\", con=engine)\n",
    "\n",
    "#reorders columns so id and name are first\n",
    "cols = ['id', 'name'] + [c for c in primary_ag_product.columns if c not in ['id', 'name']]\n",
    "\n",
    "primary_ag_product = primary_ag_product[[*cols]]\n",
    "\n",
    "primary_ag_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:08:34.613 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Extracting raw data from '03.3-CmpAna' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:08:34.613 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Extracting raw data from '03.3-CmpAna' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:08:36.203 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Successfully extracted raw data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:08:36.203 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Successfully extracted raw data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:08:36.211 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:08:36.211 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\"\", np.nan, inplace=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Resource' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     10\u001b[39m df.replace(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*$\u001b[39m\u001b[33m'\u001b[39m, np.nan, regex=\u001b[38;5;28;01mTrue\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# These are columns that need to be normalized, AKA replaced with IDs.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# This is a mapping that has first, what it is called in pandas \"resource\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# then, the SQLAlchemy model \"Resource\", and then what it is called in the\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# database \"name\"\u001b[39;00m\n\u001b[32m     19\u001b[39m NORMALIZE_COLUMNS = {\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresource\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[43mResource\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprepared_sample\u001b[39m\u001b[33m\"\u001b[39m: (PreparedSample, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpreparation_method\u001b[39m\u001b[33m\"\u001b[39m: (PreparationMethod, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m\"\u001b[39m: (Parameter, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munit\u001b[39m\u001b[33m\"\u001b[39m: (Unit, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manalyst_email\u001b[39m\u001b[33m\"\u001b[39m: (Contact, \u001b[33m\"\u001b[39m\u001b[33memail\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manalysis_type\u001b[39m\u001b[33m\"\u001b[39m: (AnalysisType, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprimary_ag_product\u001b[39m\u001b[33m\"\u001b[39m: (PrimaryAgProduct, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m }\n\u001b[32m     30\u001b[39m df_normalized = df.copy()\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Session(engine) \u001b[38;5;28;01mas\u001b[39;00m db:\n",
      "\u001b[31mNameError\u001b[39m: name 'Resource' is not defined"
     ]
    }
   ],
   "source": [
    "#This is a get_or_create type module for data normalization.\n",
    "\n",
    "# Extract a df from a gsheet\n",
    "df = cmpana.extract(project_root=project_root)\n",
    "\n",
    "# Cleans the df names and coerces data types\n",
    "df = clean_the_gsheets(df)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "\n",
    "# These are columns that need to be normalized, AKA replaced with IDs.\n",
    "# This is a mapping that has first, what it is called in pandas \"resource\"\n",
    "# then, the SQLAlchemy model \"Resource\", and then what it is called in the\n",
    "# database \"name\"\n",
    "\n",
    "\n",
    "NORMALIZE_COLUMNS = {\n",
    "    \"resource\": (Resource, \"name\"),\n",
    "    \"prepared_sample\": (PreparedSample, \"name\"),\n",
    "    \"preparation_method\": (PreparationMethod, \"name\"),\n",
    "    \"parameter\": (Parameter, \"name\"),\n",
    "    \"unit\": (Unit, \"name\"),\n",
    "    \"analyst_email\": (Contact, \"email\"),\n",
    "    \"analysis_type\": (AnalysisType, \"name\"),\n",
    "    \"primary_ag_product\": (PrimaryAgProduct, \"name\")\n",
    "}\n",
    "\n",
    "df_normalized = df.copy()\n",
    "\n",
    "with Session(engine) as db:\n",
    "    for df_col, (model, model_name_attr) in NORMALIZE_COLUMNS.items():\n",
    "        if df_col not in df_normalized.columns:\n",
    "            continue\n",
    "\n",
    "        df_normalized = replace_name_with_id_df(\n",
    "            db=db,\n",
    "            df=df_normalized,\n",
    "            ref_model=model,\n",
    "            df_name_column=df_col,\n",
    "            model_name_attr=model_name_attr,\n",
    "            id_column_name=\"id\",\n",
    "            final_column_name=f\"{df_col}_id\",\n",
    "        )\n",
    "\n",
    "    db.commit()\n",
    "\n",
    "df_normalized.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\"\", np.nan, inplace=True)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\"\", np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmp_uuid_033</th>\n",
       "      <th>record_id</th>\n",
       "      <th>prepared_sample</th>\n",
       "      <th>resource</th>\n",
       "      <th>preparation_method</th>\n",
       "      <th>storage_cond</th>\n",
       "      <th>exper_abbrev</th>\n",
       "      <th>repl_no</th>\n",
       "      <th>repl_id</th>\n",
       "      <th>parameter</th>\n",
       "      <th>...</th>\n",
       "      <th>unit</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>qc_result</th>\n",
       "      <th>note</th>\n",
       "      <th>analysis_type</th>\n",
       "      <th>equipment</th>\n",
       "      <th>raw_data_url</th>\n",
       "      <th>analyst_email</th>\n",
       "      <th>upload_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ee2993d-86e3-1f16-c7ea-f8d555e114</td>\n",
       "      <td>(85)e114</td>\n",
       "      <td>oak-tmpm01o(85)</td>\n",
       "      <td>tomato pomace</td>\n",
       "      <td>oven dry</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cmp04xk(85)1</td>\n",
       "      <td>glucan</td>\n",
       "      <td>...</td>\n",
       "      <td>% dry weight</td>\n",
       "      <td>2025-01-23 09:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compositional analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xkang2@lbl.gov</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46878ef9-1226-22a0-d5d8-cf65e241cb</td>\n",
       "      <td>(85)41cb</td>\n",
       "      <td>oak-tmpm01o(85)</td>\n",
       "      <td>tomato pomace</td>\n",
       "      <td>oven dry</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cmp04xk(85)2</td>\n",
       "      <td>glucan</td>\n",
       "      <td>...</td>\n",
       "      <td>% dry weight</td>\n",
       "      <td>2025-01-23 09:00:16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compositional analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xkang2@lbl.gov</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76a7a2f4-c4e4-e60f-1187-dec6e02246</td>\n",
       "      <td>(85)2246</td>\n",
       "      <td>oak-tmpm01o(85)</td>\n",
       "      <td>tomato pomace</td>\n",
       "      <td>oven dry</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cmp04xk(85)3</td>\n",
       "      <td>glucan</td>\n",
       "      <td>...</td>\n",
       "      <td>% dry weight</td>\n",
       "      <td>2025-01-23 09:00:31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compositional analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xkang2@lbl.gov</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a136832-286b-07cb-62de-acf52f9311</td>\n",
       "      <td>(85)9311</td>\n",
       "      <td>oak-tmpm01o(85)</td>\n",
       "      <td>tomato pomace</td>\n",
       "      <td>oven dry</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cmp04xk(85)1</td>\n",
       "      <td>glucose</td>\n",
       "      <td>...</td>\n",
       "      <td>% dry weight</td>\n",
       "      <td>2025-01-23 09:00:46</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compositional analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xkang2@lbl.gov</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b709ecee-f9a6-a55d-a59e-93b7b863d7</td>\n",
       "      <td>(85)63d7</td>\n",
       "      <td>oak-tmpm01o(85)</td>\n",
       "      <td>tomato pomace</td>\n",
       "      <td>oven dry</td>\n",
       "      <td>rt vacuum sealed</td>\n",
       "      <td>cmp04xk</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cmp04xk(85)2</td>\n",
       "      <td>glucose</td>\n",
       "      <td>...</td>\n",
       "      <td>% dry weight</td>\n",
       "      <td>2025-01-23 09:01:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compositional analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xkang2@lbl.gov</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cmp_uuid_033 record_id  prepared_sample  \\\n",
       "0  3ee2993d-86e3-1f16-c7ea-f8d555e114  (85)e114  oak-tmpm01o(85)   \n",
       "1  46878ef9-1226-22a0-d5d8-cf65e241cb  (85)41cb  oak-tmpm01o(85)   \n",
       "2  76a7a2f4-c4e4-e60f-1187-dec6e02246  (85)2246  oak-tmpm01o(85)   \n",
       "3  7a136832-286b-07cb-62de-acf52f9311  (85)9311  oak-tmpm01o(85)   \n",
       "4  b709ecee-f9a6-a55d-a59e-93b7b863d7  (85)63d7  oak-tmpm01o(85)   \n",
       "\n",
       "        resource preparation_method      storage_cond exper_abbrev  repl_no  \\\n",
       "0  tomato pomace           oven dry  rt vacuum sealed      cmp04xk      1.0   \n",
       "1  tomato pomace           oven dry  rt vacuum sealed      cmp04xk      2.0   \n",
       "2  tomato pomace           oven dry  rt vacuum sealed      cmp04xk      3.0   \n",
       "3  tomato pomace           oven dry  rt vacuum sealed      cmp04xk      1.0   \n",
       "4  tomato pomace           oven dry  rt vacuum sealed      cmp04xk      2.0   \n",
       "\n",
       "        repl_id parameter  ...          unit          created_at updated_at  \\\n",
       "0  cmp04xk(85)1    glucan  ...  % dry weight 2025-01-23 09:00:01        NaT   \n",
       "1  cmp04xk(85)2    glucan  ...  % dry weight 2025-01-23 09:00:16        NaT   \n",
       "2  cmp04xk(85)3    glucan  ...  % dry weight 2025-01-23 09:00:31        NaT   \n",
       "3  cmp04xk(85)1   glucose  ...  % dry weight 2025-01-23 09:00:46        NaT   \n",
       "4  cmp04xk(85)2   glucose  ...  % dry weight 2025-01-23 09:01:01        NaT   \n",
       "\n",
       "  qc_result note           analysis_type equipment  raw_data_url  \\\n",
       "0      pass  NaN  compositional analysis       NaN           NaN   \n",
       "1      pass  NaN  compositional analysis       NaN           NaN   \n",
       "2      pass  NaN  compositional analysis       NaN           NaN   \n",
       "3      pass  NaN  compositional analysis       NaN           NaN   \n",
       "4      pass  NaN  compositional analysis       NaN           NaN   \n",
       "\n",
       "    analyst_email upload_status  \n",
       "0  xkang2@lbl.gov         ready  \n",
       "1  xkang2@lbl.gov         ready  \n",
       "2  xkang2@lbl.gov         ready  \n",
       "3  xkang2@lbl.gov         ready  \n",
       "4  xkang2@lbl.gov         ready  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = [df, df2, df3]\n",
    "\n",
    "clean_dataframes = [clean_the_gsheets(df) for df in dataframes]\n",
    "\n",
    "clean_dataframes[2].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import select\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- project root discovery (unchanged) ---\n",
    "path = os.getcwd()\n",
    "project_root = None\n",
    "while path != os.path.dirname(path):\n",
    "    if 'pixi.toml' in os.listdir(path):\n",
    "        project_root = path\n",
    "        break\n",
    "    path = os.path.dirname(path)\n",
    "\n",
    "if not project_root:\n",
    "    raise FileNotFoundError(\"Could not find project root containing 'pixi.toml'.\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- imports ---\n",
    "from src.ca_biositing.pipeline.ca_biositing.pipeline.utils.engine import engine\n",
    "from src.ca_biositing.datamodels.ca_biositing.datamodels.schemas.generated.ca_biositing import PrimaryAgProduct\n",
    "\n",
    "# --- query + dataframe ---\n",
    "with Session(engine) as db:\n",
    "    stmt = select(*PrimaryAgProduct.__table__.columns)\n",
    "    rows = db.execute(stmt).mappings().all()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = clean_dataframes[0].\\\n",
    "    groupby(['resource', 'parameter'])['value'].\\\n",
    "        agg(['mean', 'median', 'min', 'max', 'std', 'count'])\n",
    "\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframes[0][['resource', 'parameter', 'value', 'unit']].\\\n",
    "    groupby(['resource', 'parameter', 'unit'], as_index=False).\\\n",
    "    agg({'value': 'mean'}).\\\n",
    "    query('value > 30').\\\n",
    "    sort_values(by='value', ascending=False).\\\n",
    "    round({'value': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'parameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\ca-biositing\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'parameter'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     df.loc[df[\u001b[33m'\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m'\u001b[39m].isin(list_of_param), \u001b[33m'\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mIn list\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mis_it_volatile_solids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m df[[\u001b[33m'\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mis_it_volatile_solids\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_it_volatile_solids\u001b[39m(df):\n\u001b[32m      4\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mVS\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df.loc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparameter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isin(list_of_param), \u001b[33m'\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mIn list\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\ca-biositing\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\ca-biositing\\.pixi\\envs\\default\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'parameter'"
     ]
    }
   ],
   "source": [
    "list_of_param = (\"Moisture\", \"Total solids\", \"Ash\")\n",
    "\n",
    "def is_it_volatile_solids(df):\n",
    "    df['check'] = \"VS\"\n",
    "\n",
    "    df.loc[df['parameter'].isin(list_of_param), 'check'] = \"In list\"\n",
    "    return df\n",
    "\n",
    "is_it_volatile_solids(df)\n",
    "\n",
    "df[['check', 'parameter']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This defines a function to calculate the square root of the 'value' column in a DataFrame\n",
    "def sqrtvalue(df):\n",
    "    df = df.assign(sqrtvalue = df['value'] ** 0.5)\n",
    "    return df\n",
    "\n",
    "#List comprehension to apply sqrtvalue to each DataFrame\n",
    "clean_rooted_df = [sqrtvalue(df) for df in clean_dataframes]\n",
    "\n",
    "# Display the head of the third DataFrame\n",
    "clean_rooted_df[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpana_raw = cmpana.extract(project_root=project_root)\n",
    "\n",
    "cmpana_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:10:08.640 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Extracting raw data from '03.3-CmpAna' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:10:08.640 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Extracting raw data from '03.3-CmpAna' in 'Aim 1-Feedstock Collection and Processing Data-BioCirV'...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:10:10.346 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Successfully extracted raw data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:10:10.346 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Successfully extracted raw data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:10:10.356 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:10:10.356 | \u001b[36mINFO\u001b[0m    | Task run 'extract' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Abigail\\AppData\\Local\\Temp\\ipykernel_36096\\4080610521.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\"\", np.nan, inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "replace_name_with_id_df() got an unexpected keyword argument 'name_column_name'. Did you mean 'id_column_name'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#this replaces the names with IDs\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Session(engine) \u001b[38;5;28;01mas\u001b[39;00m db:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     parameter_ids = \u001b[43mreplace_name_with_id_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mParameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_column_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# column in df + table\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mid_column_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# PK column in table\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal_column_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparameter_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m##I EVENTUALLY WANT SOME LOGS ABOUT HOW MANY WERE ADDED, HOW MANY RETRIEVED, ETC. MAYBE PUT THAT IN THE \u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#resource_id_mapping = df_with_ids.rename(columns={\"id\": \"resource_id\"})\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#resource_id_mapping\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: replace_name_with_id_df() got an unexpected keyword argument 'name_column_name'. Did you mean 'id_column_name'?"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from src.ca_biositing.pipeline.ca_biositing.pipeline.utils.engine import engine\n",
    "from src.ca_biositing.datamodels.ca_biositing.datamodels.schemas.generated.ca_biositing import *\n",
    "from src.ca_biositing.pipeline.ca_biositing.pipeline.utils.name_id_swap import (\n",
    "    replace_name_with_id_df,\n",
    ")   \n",
    "\n",
    "#This extractst the raw proximate data\n",
    "df = cmpana.extract(project_root=project_root)\n",
    "\n",
    "#this cleans the names to lowercase and parses data into a standard format. Also renames the column to match with what will be in the database\n",
    "test_df = clean_the_gsheets(df).rename(columns={'parameter': 'name'})\n",
    "\n",
    "#this replaces the names with IDs\n",
    "with Session(engine) as db:\n",
    "    parameter_ids = replace_name_with_id_df(\n",
    "        db=db,\n",
    "        df=test_df,\n",
    "        ref_model=Parameter,\n",
    "        name_column_name=\"name\",   # column in df + table\n",
    "        id_column_name=\"id\",            # PK column in table\n",
    "        final_column_name=\"parameter_id\"\n",
    "    )\n",
    "\n",
    "##I EVENTUALLY WANT SOME LOGS ABOUT HOW MANY WERE ADDED, HOW MANY RETRIEVED, ETC. MAYBE PUT THAT IN THE \n",
    "#resource_id_mapping = df_with_ids.rename(columns={\"id\": \"resource_id\"})\n",
    "\n",
    "#resource_id_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from prefect import get_run_logger\n",
    "\n",
    "resource = pd.read_sql(\"SELECT id, name FROM resource\", con=engine)\n",
    "\n",
    "resource['name'] = resource['name'].str.lower()\n",
    "\n",
    "resource['name'] = resource['name'].replace('', np.nan)\n",
    "resource.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "\n",
    "resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = pd.read_sql(\"SELECT id, name FROM resource\", con=engine)\n",
    "\n",
    "#this converts the entire dataframe to lowercase\n",
    "df = df.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_sample = pd.read_sql_query(\"SELECT * FROM field_sample\", con=engine)\n",
    "\n",
    "field_sample = field_sample[['id', 'name', 'resource_id']]\n",
    "\n",
    "field_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a get_or_create type module for data normalization.\n",
    "\n",
    "# Extract a df from a gsheet\n",
    "df = cmpana.extract(project_root=project_root)\n",
    "\n",
    "# Cleans the df names and coerces data types\n",
    "df = clean_the_gsheets(df)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "\n",
    "# These are columns that need to be normalized, AKA replaced with IDs.\n",
    "# This is a mapping that has first, what it is called in pandas \"resource\"\n",
    "# then, the SQLAlchemy model \"Resource\", and then what it is called in the\n",
    "# database \"name\"\n",
    "\n",
    "\n",
    "NORMALIZE_COLUMNS = {\n",
    "    \"resource\": (Resource, \"name\"),\n",
    "    \"prepared_sample\": (PreparedSample, \"name\"),\n",
    "    \"preparation_method\": (PreparationMethod, \"name\"),\n",
    "    \"parameter\": (Parameter, \"name\"),\n",
    "    \"unit\": (Unit, \"name\"),\n",
    "    \"analyst_email\": (Contact, \"email\"),\n",
    "    \"analysis_type\": (AnalysisType, \"name\"),\n",
    "    \"primary_ag_product\": (PrimaryAgProduct, \"name\")\n",
    "}\n",
    "\n",
    "df_normalized = df.copy()\n",
    "\n",
    "with Session(engine) as db:\n",
    "    for df_col, (model, model_name_attr) in NORMALIZE_COLUMNS.items():\n",
    "        if df_col not in df_normalized.columns:\n",
    "            continue\n",
    "\n",
    "        df_normalized = replace_name_with_id_df(\n",
    "            db=db,\n",
    "            df=df_normalized,\n",
    "            ref_model=model,\n",
    "            df_name_column=df_col,\n",
    "            model_name_attr=model_name_attr,\n",
    "            id_column_name=\"id\",\n",
    "            final_column_name=f\"{df_col}_id\",\n",
    "        )\n",
    "\n",
    "    db.commit()\n",
    "\n",
    "df_normalized.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
