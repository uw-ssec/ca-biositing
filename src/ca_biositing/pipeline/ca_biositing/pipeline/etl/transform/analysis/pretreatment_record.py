import pandas as pd
from prefect import task, get_run_logger
from ca_biositing.pipeline.utils.cleaning_functions import cleaning as cleaning_mod
from ca_biositing.pipeline.utils.cleaning_functions import coercion as coercion_mod
from ca_biositing.pipeline.utils.name_id_swap import normalize_dataframes

@task
def transform_pretreatment_record(
    raw_df: pd.DataFrame,
    etl_run_id: str | None = None,
    lineage_group_id: int | None = None
) -> pd.DataFrame:
    """
    Transforms raw DataFrame into the PretreatmentRecord table format.
    Includes cleaning, coercion, and normalization.
    """
    from ca_biositing.datamodels.models import (
        Resource,
        PreparedSample,
        Method,
        Parameter,
        Unit,
        Contact,
        Dataset,
        FileObjectMetadata,
        Experiment,
        Equipment,
        DeconVessel
    )
    logger = get_run_logger()
    logger.info("Transforming raw data for PretreatmentRecord table")

    if raw_df is None:
        logger.error("raw_df is None for PretreatmentRecord transform")
        return pd.DataFrame()

    # Handle duplicate columns
    raw_df.columns = [str(c).strip() for c in raw_df.columns]
    if "" in raw_df.columns:
        raw_df = raw_df.drop(columns=[""])

    # Pre-clean names to catch normalization-induced duplicates
    raw_df = cleaning_mod.clean_names_df(raw_df)

    if raw_df.columns.duplicated().any():
        dupes = raw_df.columns[raw_df.columns.duplicated()].unique().tolist()
        logger.warning(f"PretreatmentRecord: Duplicate columns found and removed: {dupes}")
        raw_df = raw_df.loc[:, ~raw_df.columns.duplicated()]

    # 1. Cleaning & Coercion
    df_copy = raw_df.copy()
    df_copy['dataset'] = 'bioconversion' # Assuming this is the dataset name

    cleaned_df = cleaning_mod.standard_clean(df_copy)

    if cleaned_df is None:
        logger.error("cleaning_mod.standard_clean returned None for PretreatmentRecord")
        return pd.DataFrame()

    # Add lineage IDs
    if etl_run_id is not None:
        cleaned_df['etl_run_id'] = etl_run_id
    if lineage_group_id is not None:
        cleaned_df['lineage_group_id'] = lineage_group_id

    # Mapping logic for Temperature
    # If parameter is temperature, we want to extract it to a column
    if 'parameter' in cleaned_df.columns and 'value' in cleaned_df.columns:
        temp_mask = cleaned_df['parameter'].str.contains('temperature', case=False, na=False)
        cleaned_df['temperature'] = None
        cleaned_df.loc[temp_mask, 'temperature'] = cleaned_df.loc[temp_mask, 'value']

    coerced_df = coercion_mod.coerce_columns(
        cleaned_df,
        int_cols=['repl_number'],
        float_cols=['temperature'],
        datetime_cols=['created_at', 'updated_at']
    )

    # 2. Normalization
    normalize_columns = {
        'resource': (Resource, 'name'),
        'prepared_sample': (PreparedSample, 'name'),
        'preparation_method': (Method, 'name'),
        'pretreatment_exper_name': (Experiment, 'name'),
        'decon_method_id': (Method, 'name'),
        'eh_method_id': (Method, 'name'),
        'reaction_block_id': (Equipment, 'name'),
        'analyst_email': (Contact, 'email'),
        'dataset': (Dataset, 'name'),
        'raw_data_url': (FileObjectMetadata, 'uri'),
        'vessel_id': (DeconVessel, 'name')
    }
    normalized_df = normalize_dataframes(coerced_df, normalize_columns)

    # 3. Table Specific Mapping
    rename_map = {
        'record_id': 'record_id',
        'repl_number': 'technical_replicate_no',
        'block_position': 'block_position',
        'temperature': 'temperature',
        'qc_result': 'qc_pass',
        'note': 'note',
        'etl_run_id': 'etl_run_id',
        'lineage_group_id': 'lineage_group_id'
    }

    # Handle normalized columns
    for col in normalize_columns.keys():
        norm_col = f"{col}_id"
        if norm_col in normalized_df.columns:
            target_name = 'analyst_id' if col == 'analyst_email' else \
                          'method_id' if col == 'preparation_method' else \
                          'experiment_id' if col == 'pretreatment_exper_name' else \
                          'pretreatment_method_id' if col == 'decon_method_id' else \
                          'eh_method_id' if col == 'eh_method_id' else \
                          'vessel_id' if col == 'vessel_id' else \
                          'raw_data_id' if col == 'raw_data_url' else norm_col
            rename_map[norm_col] = target_name

    available_cols = [c for c in rename_map.keys() if c in normalized_df.columns]
    final_rename = {k: v for k, v in rename_map.items() if k in available_cols}

    try:
        record_df = normalized_df[available_cols].rename(columns=final_rename).copy()

        # Add replicate_no as well if technical_replicate_no exists
        if 'technical_replicate_no' in record_df.columns:
            record_df['replicate_no'] = record_df['technical_replicate_no']

        if 'record_id' in record_df.columns:
            # Filter out placeholder or empty record_id values (like '-' or '')
            # These are often found in trailing empty rows of the spreadsheet
            record_df = record_df[~record_df['record_id'].astype(str).str.strip().isin(['-', 'nan', 'None', ''])]
            record_df = record_df.dropna(subset=['record_id'])
        else:
            logger.error("record_id missing from PretreatmentRecord transform")
            return pd.DataFrame()

        return record_df
    except Exception as e:
        logger.error(f"Error during PretreatmentRecord transform: {e}")
        return pd.DataFrame()
